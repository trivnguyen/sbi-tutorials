{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5b: Graph Neural Network NPE for Stellar Stream Analysis\n",
    "Credit: Tri Nguyen and Claude Code\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial, we implement a Neural Posterior Estimation (NPE) model using **Graph Attention Networks (GAT)** to infer dark matter subhalo parameters from stellar stream data. Unlike the MLP-based approach in Tutorial 5, this model treats stream particles as nodes in a graph and leverages graph neural networks to capture spatial relationships.\n",
    "\n",
    "**Physical Context**: Stellar streams are spatially structured - nearby particles should influence each other more than distant ones. Graph neural networks can naturally encode these relationships by:\n",
    "- Treating each particle as a graph node  \n",
    "- Creating edges between nearby particles (k-nearest neighbors)\n",
    "- Using attention mechanisms to weight particle contributions\n",
    "\n",
    "**What we'll cover:**\n",
    "- Using Graph Attention Networks (GAT) for embedding stream data\n",
    "- Training a Graph NPE model (GAT embedding + Neural Spline Flow)\n",
    "- Validating with the same coverage tests (rank-based and TARP)\n",
    "- Comparing performance to the MLP-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Simulation Data\n",
    "\n",
    "We will first load the stream data from the `data` directory. The data contains 10,000 simulated stellar streams, each with a different subhalo impact scenario. The streams are generated using the `StreamSculptor` package [Nibauer et al. (2024)](https://arxiv.org/abs/2410.21174v1).\n",
    "\n",
    "**Data Structure:**\n",
    "- `params_dict`: A dictionary containing the simulation parameters for each stream:\n",
    "  - `M_sh`: Subhalo mass in solar masses ($\\mathrm{M_\\odot}$). Shape: `(10000,)`\n",
    "  - `vz_impact`: Impact velocity in the $z$ direction (line-of-sight) in km/s. Shape: `(10000,)`\n",
    "- `streams`: The 6D phase-space coordinates of stream stars: $(x, y, z, v_x, v_y, v_z)$\n",
    "  - Shape: `(10000, N_stars, 6)` where `N_stars = 1000` for all streams in this dataset\n",
    "  \n",
    "**Physical Interpretation**: Each stream represents a tidal disruption event that has been perturbed by a passing subhalo. The subhalo mass determines the strength of the perturbation, while the impact velocity affects the timescale and spatial pattern of the disturbance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data_small.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "params_dict = data['params_dict']\n",
    "streams = data['streams']  # shape: (N_samples, N_particles, 6) # 6 corresponds to (x, y, z, vx, vy, vz)\n",
    "\n",
    "# params_dict contain two columns: M_sh (the subhalo mass) and vz_impact (the impact velocity along the line of sight)\n",
    "M_sh = params_dict['M_sh']\n",
    "vz_impact = params_dict['vz_impact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Plot a few example streams to visualize the data distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.plot(streams[i, :, 1], streams[i, :, 2], 'k.', markersize=1, alpha=0.5)\n",
    "    ax.set_title(f'Stream Example {i+1}', fontsize=16)\n",
    "    ax.set_xlabel('y [kpc]', fontsize=16)\n",
    "    ax.set_ylabel('z [kpc]', fontsize=16)\n",
    "\n",
    "    # print some info about the stream\n",
    "    text = f'M_sh: {M_sh[i]:.2e} Msun\\nvz_impact: {vz_impact[i]:.2f} km/s'\n",
    "    ax.text(0.95, 0.05, text, transform=ax.transAxes, fontsize=12,\n",
    "            va='bottom', ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Plot the distribution of the two parameters to visualize the prior distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].hist(np.log10(M_sh), bins=30, color='C0', alpha=0.7)\n",
    "axes[0].set_xlabel(r'$\\log_{10}(M_\\mathrm{sh}/\\mathrm{M}_{\\odot})$', fontsize=16)\n",
    "axes[0].set_ylabel('Frequency', fontsize=16)\n",
    "\n",
    "axes[1].hist(vz_impact, bins=30, color='C1', alpha=0.7)\n",
    "axes[1].set_xlabel('$v_{z}$ [km/s]', fontsize=16)\n",
    "axes[1].set_ylabel('Frequency', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Distributions\n",
    "\n",
    "From the histograms above, we can see that the parameters are sampled from the following distributions:\n",
    "\n",
    "- $\\log_{10} (M_\\mathrm{sh} / \\mathrm{M_\\odot}) \\sim \\mathcal{U}(6, 8)$\n",
    "- $v_{z} \\sim \\mathcal{U}(-50, 50) \\, \\mathrm{km/s}$\n",
    "\n",
    "where $\\mathcal{U}(a, b)$ denotes a uniform distribution between $a$ and $b$. \n",
    "\n",
    "**IMPORTANT**: In NPE, the distributions of parameters in the training dataset effectively define the **prior distributions** $p(\\theta)$. The trained model will learn the posterior $p(\\theta|x)$ based on these priors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph NPE: GAT embedding + NSF\n",
    "\n",
    "We will implement a Graph NPE model that uses Graph Attention Networks (GAT) for embedding and Neural Spline Flows (NSF) for density estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing the Data for Graph NPE\n",
    "\n",
    "For the Graph NPE model, we'll construct graphs **during data preparation** rather than in the training loop for efficiency. This involves:\n",
    "\n",
    "1. **Graph Construction**: Create k-NN graphs based on particle positions\n",
    "2. **Feature normalization**: Normalize particle features and parameters  \n",
    "3. **PyG Data objects**: Store each stream as a PyTorch Geometric Data object\n",
    "\n",
    "**Key difference from MLP approach**: Instead of flattening particles into vectors, we preserve the graph structure and batch using PyTorch Geometric's DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import knn_graph\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_graph(streams, params_dict, train_frac=0.9, batch_size=32, k_neighbors=10):\n",
    "    \"\"\"\n",
    "    Prepare training data for Graph NPE model.\n",
    "    Constructs graphs once during preprocessing rather than in training loop.\n",
    "\n",
    "    Returns:\n",
    "        train_loader: PyG DataLoader for training\n",
    "        val_loader: PyG DataLoader for validation\n",
    "        norm_dict: Normalization parameters\n",
    "    \"\"\"\n",
    "    N_samples, N_particles, N_features = streams.shape\n",
    "\n",
    "    # Prepare parameters (log transform mass)\n",
    "    params = np.vstack((np.log10(params_dict['M_sh']), params_dict['vz_impact'])).T\n",
    "\n",
    "    # Split into train/val\n",
    "    N_train = int(train_frac * N_samples)\n",
    "    streams_train = streams[:N_train]\n",
    "    streams_val = streams[N_train:]\n",
    "    params_train = params[:N_train]\n",
    "    params_val = params[N_train:]\n",
    "\n",
    "    print(f'Number of training samples: {N_train}')\n",
    "    print(f'Number of validation samples: {N_samples - N_train}')\n",
    "\n",
    "    # Compute normalization statistics on training data\n",
    "    X_train_flat = streams_train.reshape(N_train * N_particles, N_features)\n",
    "    X_loc = torch.tensor(X_train_flat.mean(0), dtype=torch.float32)\n",
    "    X_scale = torch.tensor(X_train_flat.std(0), dtype=torch.float32)\n",
    "\n",
    "    y_train_tensor = torch.tensor(params_train, dtype=torch.float32)\n",
    "    y_min, y_max = y_train_tensor.min(0)[0], y_train_tensor.max(0)[0]\n",
    "    y_loc = (y_min + y_max) / 2\n",
    "    y_scale = (y_max - y_min) / 2\n",
    "\n",
    "    # Create graphs for training data\n",
    "    print(\"\\nConstructing graphs for training data...\")\n",
    "    train_graphs = []\n",
    "    for i in range(N_train):\n",
    "        # Get particle data\n",
    "        particle_features = torch.tensor(streams_train[i], dtype=torch.float32)  # (N_particles, 6)\n",
    "        pos = particle_features[:, :3]  # (N_particles, 3) - positions for k-NN\n",
    "\n",
    "        # Normalize features using training statistics\n",
    "        particle_features_norm = (particle_features - X_loc) / X_scale\n",
    "\n",
    "        # Create k-NN graph based on normalized positions\n",
    "        edge_index = knn_graph(pos, k=k_neighbors, loop=True)\n",
    "\n",
    "        # Normalize parameters\n",
    "        y_norm = (torch.tensor(params_train[i], dtype=torch.float32) - y_loc) / y_scale\n",
    "        y_norm = y_norm.view(1, -1)  # (1, 2)\n",
    "\n",
    "        # Create PyG Data object\n",
    "        data = Data(\n",
    "            x=particle_features_norm,\n",
    "            edge_index=edge_index,\n",
    "            y=y_norm,\n",
    "            pos=pos\n",
    "        )\n",
    "        train_graphs.append(data)\n",
    "\n",
    "    # Create graphs for validation data\n",
    "    print(\"Constructing graphs for validation data...\")\n",
    "    val_graphs = []\n",
    "    for i in range(N_samples - N_train):\n",
    "        particle_features = torch.tensor(streams_val[i], dtype=torch.float32)\n",
    "        pos = particle_features[:, :3]\n",
    "\n",
    "        # Normalize using training statistics\n",
    "        particle_features_norm = (particle_features - X_loc) / X_scale\n",
    "        edge_index = knn_graph(pos, k=k_neighbors, loop=False)\n",
    "\n",
    "        y_norm = (torch.tensor(params_val[i], dtype=torch.float32) - y_loc) / y_scale\n",
    "        y_norm = y_norm.view(1, -1)\n",
    "\n",
    "        data = Data(\n",
    "            x=particle_features_norm,\n",
    "            edge_index=edge_index,\n",
    "            y=y_norm,\n",
    "            pos=pos\n",
    "        )\n",
    "        val_graphs.append(data)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = PyGDataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = PyGDataLoader(val_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    norm_dict = {'X_loc': X_loc, 'X_scale': X_scale, 'y_loc': y_loc, 'y_scale': y_scale}\n",
    "\n",
    "    print(\"✓ Graph construction complete!\\n\")\n",
    "    return train_loader, val_loader, norm_dict\n",
    "\n",
    "\n",
    "def subsample_streams(streams, N_particles_subsampled=100):\n",
    "    \"\"\"Subsample the streams to a fixed number of particles\"\"\"\n",
    "    N_samples, N_particles, N_features = streams.shape\n",
    "    if N_particles_subsampled >= N_particles:\n",
    "        return streams\n",
    "\n",
    "    streams_subsampled = np.zeros((N_samples, N_particles_subsampled, N_features))\n",
    "    for i in range(N_samples):\n",
    "        indices = np.random.choice(N_particles, N_particles_subsampled, replace=False)\n",
    "        streams_subsampled[i] = streams[i, indices]\n",
    "\n",
    "    return streams_subsampled\n",
    "\n",
    "# Subsample and prepare data\n",
    "streams_subsampled = subsample_streams(streams, N_particles_subsampled=100)\n",
    "train_loader, val_loader, norm_dict = prepare_training_graph(\n",
    "    streams_subsampled, params_dict, train_frac=0.9, batch_size=32, k_neighbors=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take an example batch from the validation loader and plot\n",
    "example_batch = next(iter(val_loader))\n",
    "print(example_batch)\n",
    "\n",
    "# Plot example graph\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "example_graph = example_batch[1]\n",
    "\n",
    "# plot nodes\n",
    "pos = example_graph.pos.numpy()\n",
    "ax.scatter(pos[:, 1], pos[:, 2], c='k', s=1, alpha=0.5)\n",
    "\n",
    "# plot edges\n",
    "for i in range(example_graph.edge_index.shape[1]):\n",
    "    src = example_graph.edge_index[0, i].item()\n",
    "    dst = example_graph.edge_index[1, i].item()\n",
    "    ax.plot(\n",
    "        [pos[src, 1], pos[dst, 1]], [pos[src, 2], pos[dst, 2]],\n",
    "        'C0-', alpha=0.1, zorder=-1)\n",
    "\n",
    "ax.set_title('Example Stream Graph', fontsize=16)\n",
    "ax.set_xlabel('y [kpc]', fontsize=16)\n",
    "ax.set_ylabel('z [kpc]', fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create and Train the Graph NPE Model\n",
    "\n",
    "Now we'll create our Graph NPE model and train it. The model consists of three main components:\n",
    "\n",
    "1. **Graph Construction**: Builds k-nearest neighbor graphs based on particle positions\n",
    "2. **GAT Embedding Network**: Uses graph attention layers to process the spatial structure\n",
    "   - Multiple GAT layers with multi-head attention\n",
    "   - Global mean pooling to aggregate node features\n",
    "   - Final MLP to produce fixed-size embedding\n",
    "3. **Neural Spline Flow**: Same as before - learns conditional posterior $p(\\theta|x)$\n",
    "\n",
    "**Key advantages of GAT:**\n",
    "- Captures spatial relationships between particles\n",
    "- Attention mechanism learns which particles are most informative\n",
    "- Permutation invariant (order of particles doesn't matter)\n",
    "\n",
    "For more on NPE training, see Tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import graph_npe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=50, lr=1e-3, device='cpu'):\n",
    "    \"\"\"\n",
    "    Train the NPE model given training and validation data loaders.\n",
    "    Works with PyG DataLoader that returns (batch_data, batch_params).\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    device = torch.device(device)\n",
    "    model.to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    print(f\"Training for {epochs} epochs...\\n\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        n_batches = 0\n",
    "        for batch_data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            theta_batch = batch_data.y.to(device)\n",
    "            log_prob = model.log_prob(theta_batch, batch_data.to(device))\n",
    "            loss = -log_prob.mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        avg_loss = epoch_loss / n_batches\n",
    "        train_losses.append(avg_loss)\n",
    "\n",
    "        # compute the validation loss at the end of each epoch\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0.0\n",
    "        n_val_batches = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_data in val_loader:\n",
    "                theta_val_batch = batch_data.y.to(device)\n",
    "                val_log_prob = model.log_prob(theta_val_batch, batch_data.to(device))\n",
    "                val_loss = -val_log_prob.mean()\n",
    "\n",
    "                val_epoch_loss += val_loss.item()\n",
    "                n_val_batches += 1\n",
    "        val_avg_loss = val_epoch_loss / n_val_batches\n",
    "        val_losses.append(val_avg_loss)\n",
    "\n",
    "        # print progress every epoch\n",
    "        print(f\"Epoch {epoch+1:3d}/{epochs} | Train Loss: {avg_loss:.4f} | Val Loss: {val_avg_loss:.4f}\")\n",
    "\n",
    "    print(\"\\n✓ Training complete!\")\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that training GNN models are more computationally intensive than MLPs, so training time will be longer. I highly recommend using a GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_npe_model = graph_npe.GraphNPE(\n",
    "    node_features=6,  # (x, y, z, vx, vy, vz) per particle\n",
    "    output_dim=2,  # (log10(M_sh), vz_impact)\n",
    "    hidden_size=32,\n",
    "    embedding_size=8,\n",
    "    transforms=6,\n",
    "    num_gat_layers=3,\n",
    "    heads=4\n",
    ")\n",
    "\n",
    "# note: unlike the MLP + NPE model, the Graph NPE model will require more epochs to converge\n",
    "train_losses, val_losses = train_model(\n",
    "    graph_npe_model, train_loader, val_loader, epochs=50, lr=1e-4,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'   # use GPU if available\n",
    ")\n",
    "graph_npe_model.cpu()  # move model back to CPU after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ax.plot(train_losses, label='Train Loss')\n",
    "ax.plot(val_losses, label='Validation Loss')\n",
    "ax.set_xlabel('Epoch', fontsize=16)\n",
    "ax.set_ylabel('Negative Log-Likelihood', fontsize=16)\n",
    "ax.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the loss value is significantly lower than that of the MLP-based model, indicating better fit to the data. Let's see how well the model performs in inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualizing Posterior Samples with Corner Plots\n",
    "\n",
    "Now that our model is trained, let's test it on some validation examples by sampling from the posterior $p(\\theta|x)$ and visualizing the results with corner plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install corner for visualization if needed\n",
    "try:\n",
    "    import corner\n",
    "    print(\"corner library is already installed.\")\n",
    "except ImportError:\n",
    "    !pip install corner\n",
    "    import corner\n",
    "    print(\"corner library installed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_single_obs(model, x_obs, norm_dict, n_samples=5000, k_neighbors=10):\n",
    "    \"\"\"\n",
    "    Sample from the posterior p(θ|x) for a single observation.\n",
    "    Creates graph on the fly for this single observation.\n",
    "\n",
    "    Parameters:\n",
    "    - model: trained GraphNPE model\n",
    "    - x_obs: observation (N_particles, N_features) array\n",
    "    - norm_dict: normalization parameters\n",
    "    - n_samples: number of samples to draw\n",
    "    - k_neighbors: k for k-NN graph construction\n",
    "\n",
    "    Returns:\n",
    "    - samples: (n_samples, n_params) array in original parameter space\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Convert to tensor and get shapes\n",
    "    x_obs = torch.tensor(x_obs, dtype=torch.float32)\n",
    "    N_particles, N_features = x_obs.shape\n",
    "\n",
    "    # Normalize features\n",
    "    x_obs_norm = (x_obs - norm_dict['X_loc']) / norm_dict['X_scale']\n",
    "    x_obs_norm = x_obs_norm.reshape(N_particles, N_features)\n",
    "\n",
    "    # Get normalized positions for k-NN graph\n",
    "    pos = x_obs[:, :3]\n",
    "\n",
    "    # Create k-NN graph\n",
    "    edge_index = knn_graph(pos, k=k_neighbors, loop=False)\n",
    "\n",
    "    # Create PyG Data object\n",
    "    data = Data(x=x_obs_norm, edge_index=edge_index, pos=pos)\n",
    "    batch_data = Batch.from_data_list([data])\n",
    "\n",
    "    # Sample from model\n",
    "    with torch.no_grad():\n",
    "        samples_normalized = model.sample(batch_data, n_samples)\n",
    "        samples = samples_normalized.cpu().numpy().squeeze()\n",
    "        samples = samples * norm_dict['y_scale'].numpy() + norm_dict['y_loc'].numpy()\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few test examples from validation set\n",
    "n_test_examples = 3\n",
    "test_indices = [9000, 9200, 9500]  # indices from validation set\n",
    "\n",
    "# Prepare test data (same preprocessing as training data)\n",
    "test_streams = streams_subsampled[test_indices]\n",
    "test_params = np.vstack((np.log10(M_sh[test_indices]), vz_impact[test_indices])).T\n",
    "\n",
    "print(f\"Sampling posteriors for {n_test_examples} test examples...\")\n",
    "\n",
    "# Sample from posterior for each test example\n",
    "posterior_samples = []\n",
    "for i, idx in enumerate(test_indices):\n",
    "    samples = sample_single_obs(graph_npe_model, test_streams[i], norm_dict, n_samples=10_000)\n",
    "    posterior_samples.append(samples)\n",
    "    print(f\"- Example {i+1}: log10(M_sh)={test_params[i, 0]:.2f}, vz={test_params[i, 1]:.1f} km/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the posterior samples using corner\n",
    "for i in range(n_test_examples):\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    fig = corner.corner(\n",
    "        posterior_samples[i],\n",
    "        labels=[r'$\\log_{10}(M_\\mathrm{sh}/\\mathrm{M}_{\\odot})$', r'$v_{z}$ [km/s]'],\n",
    "        truths=test_params[i],\n",
    "        show_titles=True,\n",
    "        title_fmt='.2f',\n",
    "        title_kwargs={\"fontsize\": 14},\n",
    "        label_kwargs={\"fontsize\": 14},\n",
    "        bins=20,\n",
    "        levels=(0.68, 0.95),\n",
    "        quantiles=[0.16, 0.5, 0.84],\n",
    "        smooth=1.0,\n",
    "        smooth1d=1.0,\n",
    "        color='C0',\n",
    "        truth_color='C1',\n",
    "        fig=fig\n",
    "    )\n",
    "    fig.suptitle(f'Example {i+1}', fontsize=14, y=1.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on Flow Leakage:** When using normalizing flows, be cautious of flow leakage - a phenomenon where the flow assigns non-negligible probability mass to parameter regions outside the prior bounds. This can occur when:\n",
    "- The flow's base distribution (usually Gaussian) has unbounded support while the prior is bounded\n",
    "- Training data doesn't adequately sample the prior boundaries\n",
    "- The flow architecture doesn't enforce hard constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Validation Tests\n",
    "\n",
    "Similarly with Tutorial 5a, we will perform two tests:\n",
    "1. **Predicted vs True**: Plot the predicted posterior means against the true parameter values for all validation examples. This gives a quick visual check of bias and scatter.\n",
    "2. **Coverage Tests**: Evaluate how well the predicted posteriors capture the true parameters using rank-based and TARP coverage tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_posteriors(model, loader, norm_dict, n_samples=5000):\n",
    "    \"\"\"\n",
    "    Sample from posteriors for all observations in the DataLoader.\n",
    "    Works with PyG DataLoader containing pre-constructed graphs.\n",
    "\n",
    "    Parameters:\n",
    "    - model: trained GraphNPE model\n",
    "    - loader: PyG DataLoader with graph batches\n",
    "    - norm_dict: normalization parameters\n",
    "    - n_samples: number of samples per posterior\n",
    "\n",
    "    Returns:\n",
    "    - posteriors: (n_tests, n_samples, n_params) array\n",
    "    - truths: (n_tests, n_params) array\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    posteriors_list = []\n",
    "    truths_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in loader:\n",
    "            # Sample from flow\n",
    "            samples_normalized = model.sample(batch_data, n_samples)\n",
    "\n",
    "            # zuko returns (n_samples, batch_size, output_dim)\n",
    "            # reshape to (batch_size, n_samples, output_dim)\n",
    "            samples_normalized = samples_normalized.permute(1, 0, 2)\n",
    "\n",
    "            # Denormalize\n",
    "            samples = samples_normalized.cpu().numpy()\n",
    "            samples = samples * norm_dict['y_scale'].numpy() + norm_dict['y_loc'].numpy()\n",
    "            posteriors_list.append(samples)\n",
    "\n",
    "            # Get true parameters\n",
    "            truths = batch_data.y.cpu().numpy()\n",
    "            truths = truths * norm_dict['y_scale'].numpy() + norm_dict['y_loc'].numpy()\n",
    "            truths_list.append(truths)\n",
    "\n",
    "    posteriors = np.concatenate(posteriors_list, axis=0)\n",
    "    truths = np.concatenate(truths_list, axis=0)\n",
    "\n",
    "    return posteriors, truths\n",
    "\n",
    "\n",
    "posterior_samples_all, truths_all = sample_posteriors(\n",
    "    graph_npe_model, val_loader, norm_dict, n_samples=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first plot the predicted vs true values for both parameters across all validation examples. Ideally, points should lie along the diagonal line, indicating accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Compute point estimates (median) and uncertainties (16th and 84th percentiles)\n",
    "predicted_median, predicted_lower, predicted_upper = np.percentile(\n",
    "    posterior_samples_all, [50, 16, 84], axis=1)\n",
    "\n",
    "# True vs Predicted for log10(M_sh)\n",
    "axes[0].errorbar(\n",
    "    truths_all[:, 0],\n",
    "    predicted_median[:, 0],\n",
    "    yerr=[predicted_median[:, 0] - predicted_lower[:, 0],\n",
    "          predicted_upper[:, 0] - predicted_median[:, 0]],\n",
    "    fmt='o', markersize=4, alpha=0.5, label='Predictions',\n",
    "    zorder=0\n",
    ")\n",
    "axes[0].plot([6, 8], [6, 8], 'k--', lw=2, zorder=1)\n",
    "axes[0].set_xlabel(r'True $\\log_{10}(M_{sh})$', fontsize=16)\n",
    "axes[0].set_ylabel(r'Predicted $\\log_{10}(M_{sh})$', fontsize=16)\n",
    "\n",
    "# True vs Predicted for vz_impact\n",
    "axes[1].errorbar(\n",
    "    truths_all[:, 1],\n",
    "    predicted_median[:, 1],\n",
    "    yerr=[predicted_median[:, 1] - predicted_lower[:, 1],\n",
    "          predicted_upper[:, 1] - predicted_median[:, 1]],\n",
    "    fmt='o', markersize=4, alpha=0.5, label='Predictions',\n",
    "    zorder=0\n",
    ")\n",
    "axes[1].plot([-50, 50], [-50, 50], 'k--', lw=2, zorder=1)\n",
    "axes[1].set_xlabel(r'True $v_z$ [km/s]', fontsize=16)\n",
    "axes[1].set_ylabel(r'Predicted $v_z$ [km/s]', fontsize=16)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's validate our NPE model using the calibration tests from Tutorial 04:\n",
    "- **Rank-based test**: Checks if marginal posteriors are well-calibrated\n",
    "- **TARP**: Tests joint posterior calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "\n",
    "# Install tarp for coverage tests if needed\n",
    "try:\n",
    "    import tarp\n",
    "    print(\"tarp library is already installed.\")\n",
    "except ImportError:\n",
    "    !pip install deprecation tarp\n",
    "    import tarp\n",
    "    print(\"tarp library installed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank-based Test\n",
    "See Tutorial 04 for details on the rank-based calibration test. We'll apply it separately for each parameter, since this test only works for 1D marginals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_based_calibration(theta_true, theta_samples):\n",
    "    \"\"\"\n",
    "    Compute ranks for the rank-based calibration test.\n",
    "\n",
    "    Parameters:\n",
    "    - theta_true: (n_tests,) array of true parameter values\n",
    "    - theta_samples: (n_tests, n_samples) array of posterior samples\n",
    "\n",
    "    Returns:\n",
    "    - ranks: (n_tests,) array of ranks (normalized to [0, 1])\n",
    "    \"\"\"\n",
    "    n_tests, n_samples = theta_samples.shape\n",
    "\n",
    "    # For each test case, count how many samples are less than the true value\n",
    "    ranks = np.sum(theta_samples < theta_true.reshape(-1, 1), axis=1)\n",
    "\n",
    "    # Normalize ranks to [0, 1]\n",
    "    normalized_ranks = ranks / n_samples\n",
    "\n",
    "    return normalized_ranks\n",
    "\n",
    "# Compute ranks for each parameter separately\n",
    "ranks_log_mass = rank_based_calibration(truths_all[:, 0], posterior_samples_all[:, :, 0])\n",
    "ranks_vz = rank_based_calibration(truths_all[:, 1], posterior_samples_all[:, :, 1])\n",
    "\n",
    "print(\"Rank-based Calibration Statistics:\")\n",
    "print(f\"\\nlog10(M_sh):\")\n",
    "print(f\"  Mean: {ranks_log_mass.mean():.3f} (expected: 0.500)\")\n",
    "print(f\"  Std:  {ranks_log_mass.std():.3f} (expected: {1/np.sqrt(12):.3f})\")\n",
    "print(f\"\\nvz:\")\n",
    "print(f\"  Mean: {ranks_vz.mean():.3f} (expected: 0.500)\")\n",
    "print(f\"  Std:  {ranks_vz.std():.3f} (expected: {1/np.sqrt(12):.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "param_names = [r'$\\log_{10}(M_{\\rm sh}/M_{\\odot})$', r'$v_z$ [km/s]']\n",
    "all_ranks = [ranks_log_mass, ranks_vz]\n",
    "\n",
    "for param_idx, (ranks, param_name) in enumerate(zip(all_ranks, param_names)):\n",
    "    # Histogram\n",
    "    ax = axes[param_idx, 0]\n",
    "    ax.hist(ranks, bins=30, color=f'C{param_idx}', density=True, alpha=0.7)\n",
    "    ax.axhline(1.0, color='black', linestyle='--', linewidth=2, label='Uniform (expected)')\n",
    "    ax.set_xlabel('Normalized Rank', fontsize=14)\n",
    "    ax.set_ylabel('Density', fontsize=14)\n",
    "    ax.set_title(f'Rank Distribution: {param_name}', fontsize=14)\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.set_ylim([0, 2.5])\n",
    "\n",
    "    # Q-Q plot\n",
    "    ax = axes[param_idx, 1]\n",
    "    sorted_ranks = np.sort(ranks)\n",
    "    theoretical_quantiles = np.linspace(0, 1, len(sorted_ranks))\n",
    "    ax.plot(theoretical_quantiles, sorted_ranks, '-', lw=2, color=f'C{param_idx}')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration', linewidth=2)\n",
    "\n",
    "    # Confidence bands (1, 2, 3 sigma)\n",
    "    n = len(ranks)\n",
    "    se = 1 / np.sqrt(12 * n)\n",
    "    sigmas = [1, 2, 3]\n",
    "    alphas = [0.4, 0.3, 0.2]\n",
    "    quantiles = np.linspace(0, 1, 100)\n",
    "    for sigma, alpha_val in zip(sigmas, alphas):\n",
    "        lower_band = np.maximum(quantiles - sigma * se, 0)\n",
    "        upper_band = np.minimum(quantiles + sigma * se, 1)\n",
    "        ax.fill_between(quantiles, lower_band, upper_band, alpha=alpha_val, color='gray')\n",
    "\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.set_xlabel('Expected Quantiles', fontsize=14)\n",
    "    ax.set_ylabel('Observed Quantiles', fontsize=14)\n",
    "    ax.set_title(f'Q-Q Plot: {param_name}', fontsize=14)\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Kolmogorov-Smirnov test\n",
    "ks_stat_mass, p_value_mass = kstest(ranks_log_mass, 'uniform')\n",
    "ks_stat_vz, p_value_vz = kstest(ranks_vz, 'uniform')\n",
    "\n",
    "print(f\"\"\"Kolmogorov-Smirnov Test Results\n",
    "(Tests if ranks are uniformly distributed)\n",
    "\n",
    "log10(M_sh):\n",
    "  KS statistic: {ks_stat_mass:.4f}\n",
    "  p-value: {p_value_mass:.4f}\n",
    "  {'✓ Well calibrated' if p_value_mass > 0.05 else '✗ Poor calibration'}\n",
    "\n",
    "vz:\n",
    "  KS statistic: {ks_stat_vz:.4f}\n",
    "  p-value: {p_value_vz:.4f}\n",
    "  {'✓ Well calibrated' if p_value_vz > 0.05 else '✗ Poor calibration'}\n",
    "\n",
    "Note: p-value > 0.05 suggests good calibration\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TARP Calibration Test\n",
    "\n",
    "See Tutorial 04 for details on TARP ([Lemos et al. 2023](https://arxiv.org/abs/2302.03026)). Unlike the rank-based test, TARP can detect miscalibration in the joint posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TARP coverage test\n",
    "print(\"Running TARP coverage test...\")\n",
    "print(\"This may take a minute...\\n\")\n",
    "\n",
    "# TARP expects shape: (n_samples, n_tests, n_params)\n",
    "# We have: (n_tests, n_samples, n_params)\n",
    "# So we need to transpose the first two dimensions\n",
    "tarp_samples = np.transpose(posterior_samples_all, (1, 0, 2))\n",
    "\n",
    "ecp, alpha = tarp.get_tarp_coverage(\n",
    "    tarp_samples,  # shape: (n_samples, n_tests, n_params)\n",
    "    truths_all,    # shape: (n_tests, n_params)\n",
    "    bootstrap=True,\n",
    "    num_bootstrap=100\n",
    ")\n",
    "\n",
    "print(\"✓ TARP test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot TARP Expected Coverage Probability (ECP) curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "\n",
    "# Plot the mean ECP curve\n",
    "ax.plot(alpha, ecp.mean(axis=0), label='Observed Coverage', color='C0', linewidth=3)\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration', linewidth=2)\n",
    "\n",
    "# Plot confidence bands (1, 2, 3 sigma) from bootstrap\n",
    "sigmas = [1, 2, 3]\n",
    "alphas_fill = [0.4, 0.3, 0.2]\n",
    "for k, alpha_val in zip(sigmas, alphas_fill):\n",
    "    ax.fill_between(\n",
    "        alpha,\n",
    "        ecp.mean(axis=0) - k * ecp.std(axis=0),\n",
    "        ecp.mean(axis=0) + k * ecp.std(axis=0),\n",
    "        color='C0', alpha=alpha_val,\n",
    "    )\n",
    "\n",
    "# Add reference curves for over/under-confident\n",
    "x_region = np.linspace(0, 1, 100)\n",
    "overconfident_curve = x_region + 0.15 * np.sin(2 * np.pi * x_region)\n",
    "underconfident_curve = x_region - 0.15 * np.sin(2 * np.pi * x_region)\n",
    "ax.plot(x_region, overconfident_curve, color='red', ls='dotted',\n",
    "        linewidth=2, alpha=0.5, label='Overconfident (example)')\n",
    "ax.plot(x_region, underconfident_curve, color='blue', ls='dashdot',\n",
    "        linewidth=2, alpha=0.5, label='Underconfident (example)')\n",
    "\n",
    "ax.set_xlabel('Credibility Level', fontsize=16)\n",
    "ax.set_ylabel('Expected Coverage Probability', fontsize=16)\n",
    "ax.legend(fontsize=12, loc='upper left')\n",
    "ax.grid(alpha=0.3, linestyle='--')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, in this example, we find that the model passes the rank-based test for both parameters but fails the TARP test. This indicates that while the marginal posteriors are well-calibrated, the joint posterior has miscalibration issues that the rank-based test cannot detect. This highlights the importance of using joint calibration tests like TARP when validating multi-parameter inference models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this tutorial, we implemented a Graph Neural Network-based NPE model using Graph Attention Networks (GAT) for embedding stellar stream data. This approach leverages the spatial structure of the streams by treating particles as nodes in a graph and using attention mechanisms to capture local correlations.\n",
    "\n",
    "We find that the model can recover subhalo parameters with better accuracy than the MLP approach. However, calibration tests indicate some miscalibration in the joint posterior. This highlights that posterior calibration can be much more challenging than point estimation and persists even with more sophisticated architectures. Further improvements could include:\n",
    "- Tuning GAT architecture and hyperparameters\n",
    "- Increasing the number of training samples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
